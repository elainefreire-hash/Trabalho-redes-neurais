# Trabalho de Redes Neurais

Este reposit√≥rio cont√©m o projeto **"Classifica√ß√£o de Doen√ßas Card√≠acas"**, desenvolvido como parte das atividades acad√™micas da disciplina de Fundamentos de Intelig√™ncia Artificial no Instituto de Computa√ß√£o da Universidade Federal do Amazonas (IComp/UFAM).

## üë• Equipe

| Nome | E-mail |
|------|---------|
| Anna Luisa Antony Afonso | anna.antony@icomp.ufam.edu.br |
| Beatriz Quaresma Athaide | beatriz.quaresma@icomp.ufam.edu.br |
| Elaine de Castro Freire | elaine.freire@icomp.ufam.edu.br |
| Manuela Figueira Batista | manuela.batista@icomp.ufam.edu.br |
| Ra√≠ssa Clara Teixeira Brasil | raissa.brasil@icomp.ufam.edu.br |
| Ruthelene Rodrigues Farias | ruthelene.farias@icomp.ufam.edu.br |

# ü´Ä Classifica√ß√£o de Doen√ßas Card√≠acas com Redes Neurais


Este projeto implementa e avalia um modelo de Rede Neural Sequencial (utilizando Keras) para a classifica√ß√£o bin√°ria de doen√ßa card√≠aca com base em dados cl√≠nicos. O objetivo √© configurar um ambiente robusto, limpar e pr√©-processar o dataset Cleveland, treinar um modelo de Deep Learning e otimiz√°-lo com t√©cnicas de regulariza√ß√£o para garantir a capacidade de generaliza√ß√£o. 

# 1. üõ†Ô∏è Inicializa√ß√£o e Carregamento de Dados

Este bloco de c√≥digo marca o in√≠cio de qualquer projeto robusto de Machine Learning (ML), estabelecendo as bases do ambiente de software e preparando as ferramentas necess√°rias para as fases de pr√©-processamento, an√°lise e modelagem.

***

### Verifica√ß√£o e Gerenciamento de Depend√™ncias

O primeiro objetivo do c√≥digo √© importar todas as bibliotecas Python que servir√£o como a espinha dorsal do projeto. Imediatamente ap√≥s a importa√ß√£o, o c√≥digo imprime as vers√µes de cada uma das principais ferramentas. Essa pr√°tica de **versionamento** √© crucial para garantir a **reprodutibilidade** do ambiente. Caso o c√≥digo precise ser executado em outra m√°quina ou em uma data futura, ter as vers√µes exatas documentadas permite diagnosticar e prevenir erros de compatibilidade.

As bibliotecas importadas e verificadas incluem:

* **`sys`:** Essencialmente para obter informa√ß√µes sobre o ambiente de execu√ß√£o, especialmente a vers√£o do **Python** em uso.
* **`pandas`:** A ferramenta prim√°ria para lidar com **dados tabulares**, convertendo dados brutos em estruturas DataFrames f√°ceis de manipular, limpar e analisar.
* **`numpy`:** Fornece a base para **opera√ß√µes num√©ricas** de alto desempenho, sendo o formato de array fundamental que a maioria dos algoritmos de ML consome.
* **`sklearn` (Scikit-learn):** A biblioteca mais popular para tarefas de ML cl√°ssico, oferecendo uma vasta gama de algoritmos de **classifica√ß√£o**, **regress√£o** e **agrupamento**, al√©m de utilit√°rios para pr√©-processamento.
* **`matplotlib`:** A biblioteca de refer√™ncia para a **cria√ß√£o de gr√°ficos** e visualiza√ß√µes de dados, permitindo a constru√ß√£o de histogramas, gr√°ficos de linha e gr√°ficos de barras.
* **`keras`:** Uma interface de alto n√≠vel usada para construir e treinar **Redes Neurais** de maneira eficiente e amig√°vel.

***

### Prepara√ß√£o para Visualiza√ß√£o e Acesso a Dados

A se√ß√£o seguinte, conforme descrito na sua explica√ß√£o, foca em configurar o acesso aos dados e armar o ambiente com as ferramentas de An√°lise Explorat√≥ria de Dados (EDA).

* **Montagem do Google Drive:** Em plataformas de *notebook* baseadas em nuvem, este comando √© fundamental para **conectar o ambiente de c√≥digo** aos arquivos de dados do projeto, permitindo que os dados brutos sejam carregados.
* **Importa√ß√µes Gr√°ficas Avan√ßadas:**
    * As importa√ß√µes de **`matplotlib.pyplot`** e **`seaborn`** s√£o feitas para equipar o projeto com capacidades de visualiza√ß√£o de dados. O `seaborn` √© constru√≠do sobre o `matplotlib` e permite criar **gr√°ficos estat√≠sticos complexos** com menos c√≥digo, sendo ideal para a EDA.
    * A importa√ß√£o de **`pandas.plotting.scatter_matrix`** √© um atalho pr√°tico para gerar uma **matriz de gr√°ficos de dispers√£o**, o que permite inspecionar rapidamente as rela√ß√µes de correla√ß√£o entre todos os pares de vari√°veis num√©ricas do *dataset*.

Em resumo, o bloco de "Inicializa√ß√£o e Carregamento de Dados" est√° configurando o *pipeline* do projeto. Ele verifica a integridade do ambiente, garante que o acesso √† fonte de dados esteja estabelecido e importa as bibliotecas especializadas que ser√£o usadas nas pr√≥ximas etapas de An√°lise Explorat√≥ria e Modelagem.

# 2. üìä Importa√ß√£o e Explora√ß√£o do Dataset
O foco desta etapa √© a limpeza, transforma√ß√£o e an√°lise explorat√≥ria dos dados brutos.


| Etapa                     | Descri√ß√£o                                                                                                                                                                                                                                                                          | Import√¢ncia                                                                                     |
|---------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| Carregamento e Limpeza    | O dataset √© carregado (ex: 303 amostras, 14 colunas). Valores ausentes, codificados como '?', s√£o substitu√≠dos por NaN e, em seguida, as linhas com valores nulos s√£o removidas (resultando em ‚âà297 linhas).                                                                        | Garante a integridade dos dados e remove inconsist√™ncias.                                        |
| Transforma√ß√£o de Tipo     | Todas as colunas s√£o convertidas do tipo object para tipos num√©ricos (int64 ou float64), passo fundamental para permitir o c√°lculo e a modelagem.                                                                                                                                   | Essencial para o uso em algoritmos de Machine Learning.                                         |
| Estat√≠sticas Descritivas  | data.describe() gera um resumo estat√≠stico (mean, std, min, max), crucial para identificar a escala das vari√°veis e planejar o scaling.                                                                                                                                             | Auxilia na detec√ß√£o de outliers e no pr√©-processamento.                                         |
| An√°lise de Distribui√ß√£o   | data.hist() plota histogramas para a an√°lise visual da distribui√ß√£o de frequ√™ncia de cada vari√°vel.                                                                                                                                                                                  | Essencial para verificar o balanceamento da classe alvo (target).                               |
| An√°lise de Correla√ß√£o     | A matriz de correla√ß√£o de Pearson √© calculada e visualizada em um Heatmap.                                                                                                                                                                                                          | Identifica os preditores mais fortes (alta correla√ß√£o com target) e a multicolinearidade.       |
| An√°lise Espec√≠fica        | pd.crosstab e gr√°ficos de barras/pontos exploram rela√ß√µes cruciais (ex: casos positivos/negativos por idade, e a tend√™ncia de thalach (frequ√™ncia card√≠aca m√°xima) em rela√ß√£o √† idade).                                                                                              | Oferece insights diretos e valida a coer√™ncia fisiol√≥gica dos dados.                             |

---
### Detalhamento das Etapas de Pr√©-processamento

#### 1. Limpeza e Integridade dos Dados

O processo de carregamento utiliza o `pandas` para ler o arquivo `heart.csv`. A inspe√ß√£o inicial revela que o *dataset* cont√©m valores ausentes codificados de forma n√£o padr√£o (o caractere **'?'**). O c√≥digo soluciona este problema **substituindo** e, em seguida, **removendo** as linhas que continham esses valores inv√°lidos (`dropna`). Adicionalmente, a remo√ß√£o de **linhas duplicadas** √© realizada para garantir que o modelo n√£o seja treinado com informa√ß√µes redundantes, o que poderia enviesar a avalia√ß√£o de desempenho.

#### 2. Normaliza√ß√£o de Tipos e Estat√≠stica Descritiva

A convers√£o de tipos de dados (`data.apply(pd.to_numeric)`) √© um passo n√£o negoci√°vel no pr√©-processamento, pois garante que todas as colunas estejam em formato **num√©rico** (`int64` ou `float64`), requisito b√°sico para o c√°lculo de dist√¢ncia e otimiza√ß√£o em algoritmos de Machine Learning. Uma vez limpo e tipado, o DataFrame √© resumido pelo **`data.describe()`**. Este resumo estat√≠stico √© inspecionado para:
* Confirmar a **escala** de cada vari√°vel.
* Avaliar a **dispers√£o** (`std`).
* Identificar **valores extremos** (*outliers*) nos valores m√≠nimos e m√°ximos, que podem exigir tratamento especializado (como *winsorizing* ou logaritmiza√ß√£o) posteriormente.

---

### Detalhamento da An√°lise Explorat√≥ria (EDA)

A EDA √© a fase visual e estat√≠stica que fundamenta as decis√µes de modelagem:

#### Distribui√ß√µes e Frequ√™ncias
A gera√ß√£o de **histogramas** (`data.hist()`) √© utilizada para visualizar a distribui√ß√£o de frequ√™ncia de cada vari√°vel. Esta an√°lise √© essencial para entender se os dados seguem uma **distribui√ß√£o normal** e, sobretudo, para inspecionar o **balanceamento da vari√°vel alvo (`target`)**. Um *target* desbalanceado (onde uma classe √© muito mais frequente que a outra) pode levar o modelo a ser enviesado, necessitando de t√©cnicas de reamostragem como SMOTE.

#### An√°lise de Rela√ß√µes e Coer√™ncia
* **Correla√ß√£o (Heatmap):** A matriz de correla√ß√£o de Pearson, exibida como um **Heatmap**, permite identificar de forma r√°pida quais vari√°veis t√™m a **maior rela√ß√£o linear** com o `target`. Al√©m disso, √© o principal m√©todo para detectar a **multicolinearidade** (correla√ß√£o alta entre dois preditores independentes), que pode inflacionar a vari√¢ncia e prejudicar a interpretabilidade de modelos como Regress√£o Log√≠stica.
* **Idade vs. Doen√ßa (`pd.crosstab`):** O cruzamento da vari√°vel categ√≥rica `age` com o `target` √© plotado para identificar as **faixas et√°rias de maior risco**. Este *insight* direto valida a import√¢ncia preditiva dessa *feature*.
* **Valida√ß√£o Fisiol√≥gica (`thalach` vs. Idade):** A plotagem da frequ√™ncia card√≠aca m√°xima (`thalach`) em fun√ß√£o da idade √© uma etapa de **valida√ß√£o de qualidade**. A expectativa √© que essa vari√°vel **diminua** com o avan√ßo da idade, um comportamento fisiol√≥gico conhecido. A confirma√ß√£o dessa tend√™ncia no *dataset* atesta a coer√™ncia e a integridade dos dados coletados.

# 3. üß† Cria√ß√£o dos Dados de Treinamento

Este bloco de c√≥digo √© o ponto de transi√ß√£o crucial entre a An√°lise Explorat√≥ria de Dados (EDA) e a fase de Modelagem. Ele cobre as etapas essenciais de **estrutura√ß√£o, divis√£o e escalonamento** das vari√°veis, garantindo que o *dataset* esteja no formato ideal para o treinamento e a avalia√ß√£o dos algoritmos de Machine Learning.

### 1. Separa√ß√£o de Vari√°veis e Convers√£o para NumPy

A primeira a√ß√£o do c√≥digo √© estabelecer o problema de classifica√ß√£o atrav√©s da separa√ß√£o formal das vari√°veis. A coluna **`target`** √© isolada para formar a vari√°vel **y** (o r√≥tulo, ou o que deve ser previsto), enquanto todas as demais colunas do DataFrame, que representam as caracter√≠sticas cl√≠nicas, s√£o agrupadas na matriz **X** (os preditores). O c√≥digo, em seguida, realiza a convers√£o imediata de **X** e **y** para **NumPy Arrays**. Essa convers√£o √© um requisito t√©cnico fundamental, pois o NumPy √© o formato de matriz de alto desempenho exigido por praticamente todas as bibliotecas de Machine Learning, como Scikit-learn e Keras, otimizando o consumo de mem√≥ria e a velocidade dos c√°lculos. A inspe√ß√£o inicial de `X[0]` confirma que o processo de separa√ß√£o ocorreu com sucesso e que os dados num√©ricos est√£o estruturados corretamente.

### 2. Divis√£o Estratificada dos Dados (*Train-Test Split*)

A pr√≥xima etapa √© a divis√£o dos dados em conjuntos de **treinamento (`X_train`, `y_train`)** e **teste (`X_test`, `y_test`)**. O padr√£o utilizado √© de **80%** dos dados para treinamento e **20%** para teste (`test_size=0.2`). Esta separa√ß√£o √© vital para que o modelo seja treinado em uma por√ß√£o dos dados e avaliado em uma por√ß√£o **in√©dita**, fornecendo uma estimativa imparcial de seu desempenho em novos dados. O uso do par√¢metro **`stratify=y` √© absolutamente cr√≠tico** neste contexto de classifica√ß√£o. Ele assegura que a **propor√ß√£o da classe alvo** (pacientes com e sem a doen√ßa card√≠aca) seja **mantida de forma id√™ntica** nos subconjuntos de treino e teste.  Sem a estratifica√ß√£o, o conjunto de teste poderia, por acaso, conter uma propor√ß√£o desequilibrada das classes, resultando em uma avalia√ß√£o de desempenho irrealista ou tendenciosa.

### 3. Padroniza√ß√£o de Caracter√≠sticas (*Standard Scaling*) e Preven√ß√£o de *Data Leakage*

A etapa final e mais sofisticada de pr√©-processamento √© a **padroniza√ß√£o** das caracter√≠sticas (`StandardScaler`). Este m√©todo transforma os dados de forma que cada caracter√≠stica tenha uma **m√©dia pr√≥xima de zero e um desvio padr√£o pr√≥ximo de um**. Isso √© essencial para algoritmos que calculam dist√¢ncias entre pontos (como k-Nearest Neighbors, KNN) ou para modelos baseados em otimiza√ß√£o por gradiente (como Redes Neurais), pois impede que *features* com escalas naturalmente maiores (como a idade) dominem o processo de aprendizado.

O processo de *scaling* √© aplicado em duas fases obrigat√≥rias para **prevenir o vazamento de dados (*data leakage*)**:

1.  **Ajuste e Transforma√ß√£o no Treino:** O *scaler* √© **ajustado** e **transformado** (`fit_transform`) **somente** no conjunto de treinamento (`X_train`). Isso significa que a m√©dia e o desvio padr√£o usados para a padroniza√ß√£o s√£o derivados **exclusivamente** dos dados de treino.
2.  **Transforma√ß√£o no Teste:** Os **mesmos par√¢metros** (m√©dia e desvio padr√£o) aprendidos no conjunto de treino s√£o, ent√£o, usados para **transformar** (`transform`) o conjunto de teste (`X_test`).

Essa separa√ß√£o garante que o modelo de avalia√ß√£o (`X_test`) permane√ßa totalmente desconhecido em todas as etapas, simulando com precis√£o o cen√°rio real onde o modelo encontrar√° dados novos. A verifica√ß√£o final do `X[0]` no c√≥digo serve para confirmar que a matriz original **X** n√£o foi modificada pelo `StandardScaler`, mantendo a integridade do *array* principal.      
## üìÑ 4 - Treinamento da Rede Neural

Esta documenta√ß√£o abrange o desenvolvimento completo do modelo de **Deep Learning**, desde a garantia de um ambiente **reprodut√≠vel** at√© a aplica√ß√£o de **t√©cnicas avan√ßadas de regulariza√ß√£o** e a **an√°lise visual** do desempenho. O objetivo √© criar um modelo robusto, com alta capacidade de generaliza√ß√£o e evitar o *overfitting*.

---

### 4.1. Garantia de Reprodutibilidade (*Seeding*) e Prepara√ß√£o do Alvo

O bloco inicial √© essencialmente t√©cnico, focando na **garantia de reprodutibilidade** do experimento. A defini√ß√£o de uma **semente fixa (`SEED = 42`)** e sua aplica√ß√£o sistem√°tica nos geradores de n√∫meros pseudo-aleat√≥rios do **Python (`random`)**, **NumPy (`np.random`)** e **TensorFlow (`tf.random`)** asseguram que todas as execu√ß√µes subsequentes do c√≥digo, incluindo a inicializa√ß√£o dos pesos da rede e a sequ√™ncia de *dropout*, resultar√£o nos mesmos valores. Isso permite a compara√ß√£o consistente dos resultados e a valida√ß√£o do processo de otimiza√ß√£o.

O bloco seguinte prepara a vari√°vel alvo (`y`) para o formato **bin√°rio estrito**. C√≥pias dos r√≥tulos de treino (`y_train`) e teste (`y_test`) s√£o criadas e, em seguida, todos os valores **maiores que zero** s√£o explicitamente convertidos para **1** (`Doente`), enquanto a aus√™ncia de doen√ßa permanece **0** (`Saud√°vel`). Esta convers√£o √© **fundamental** para a utiliza√ß√£o da fun√ß√£o de perda **`binary_crossentropy`**, que exige r√≥tulos de classe estritamente 0 ou 1. A impress√£o dos primeiros 20 elementos de `Y_train_binary` confirma a **integridade** desta convers√£o.

---

### 4.2. Defini√ß√£o da Arquitetura Otimizada (Regulariza√ß√£o Refor√ßada)

O c√≥digo define uma fun√ß√£o construtora para a **Rede Neural Sequencial Otimizada** (`create_binary_model_tuned`), com um foco expl√≠cito no combate ao *overfitting* atrav√©s de regulariza√ß√£o avan√ßada. A arquitetura √© constru√≠da com tr√™s camadas ocultas, introduzindo maior profundidade e complexidade para a rede:

* **Camadas Ocultas:** S√£o tr√™s camadas (`Dense`) com **16, 8 e 4 neur√¥nios** respectivamente, todas utilizando a fun√ß√£o de ativa√ß√£o **ReLU** (Rectified Linear Unit), ideal para camadas intermedi√°rias. O `input_shape=(13,)` confirma o n√∫mero de caracter√≠sticas de entrada ap√≥s o pr√©-processamento.
* **Regulariza√ß√£o L2 ($\ell_2$):** Um termo de penalidade $\ell_2(0.001)$ √© aplicado aos *kernels* (pesos) de cada camada densa (`kernel_regularizer`). Esta t√©cnica for√ßa os pesos a serem menores e mais esparsos, **mitigando o *overfitting*** ao simplificar o modelo.
* **Dropout Refor√ßado:** Uma alta taxa de **`Dropout(0.25)`** √© aplicada entre *cada* camada densa. Este valor elevado aumenta a desativa√ß√£o aleat√≥ria de 25% dos neur√¥nios durante o treinamento, o que impede a co-adapta√ß√£o e refor√ßa a generaliza√ß√£o do modelo.
* **Compila√ß√£o e Otimizador:** O modelo √© compilado com a perda **`binary_crossentropy`** e o otimizador **Adam** configurado com um **`learning_rate` baixo (0.0005)**. Esta taxa de aprendizado reduzida permite um ajuste mais fino e est√°vel dos pesos, otimizando a converg√™ncia.

O **`binary_model.summary()`** impresso no final do bloco fornece uma verifica√ß√£o da arquitetura, incluindo a contagem de par√¢metros trein√°veis. 

---

### 4.3. Treinamento Controlado e *Early Stopping*

O treinamento do modelo √© realizado sob um rigoroso controle atrav√©s do *callback* **`EarlyStopping`**. Esta t√©cnica √© fundamental para **evitar o *overfitting***, parando o treinamento no ponto de m√°xima generaliza√ß√£o.

* **M√©trica Monitorada:** O *Early Stopping* monitora a **perda de valida√ß√£o (`val_loss`)**, que √© a m√©trica mais sens√≠vel para detectar o in√≠cio do *overfitting*.
* **Paci√™ncia (`patience=10`):** O treinamento ser√° interrompido se a perda de valida√ß√£o n√£o apresentar melhora ap√≥s **10 √©pocas consecutivas**.
* **Restaura√ß√£o de Pesos:** O par√¢metro **`restore_best_weights=True`** garante que, mesmo ap√≥s a interrup√ß√£o, o modelo retorne e utilize os pesos da √©poca que resultou no **melhor desempenho de valida√ß√£o**, e n√£o os pesos da √∫ltima √©poca, que j√° podem ter sofrido *overfitting* leve.

O modelo (`binary_model`) √© treinado por no m√°ximo **50 √©pocas** com um **`batch_size` de 32**. O uso do `validation_data` (conjunto de teste) junto ao `EarlyStopping` cria um processo de treinamento eficiente e robusto.

---

### 4.4. An√°lise Visual de Converg√™ncia e Generaliza√ß√£o

O bloco final gera uma figura com dois gr√°ficos de linha lado a lado para visualizar o desempenho do modelo, utilizando o hist√≥rico (`history`) registrado durante o treinamento:

1.  **Acur√°cia do Modelo:** Compara a acur√°cia no **conjunto de treinamento** com a acur√°cia no **conjunto de valida√ß√£o**.
2.  **Perda (*Loss*) do Modelo:** Compara a perda no **conjunto de treinamento** com a perda no **conjunto de valida√ß√£o**.

A **an√°lise visual** destas curvas √© o resultado final e a valida√ß√£o das otimiza√ß√µes. Uma **dist√¢ncia pequena (gap)** entre as curvas de treino e valida√ß√£o √© a confirma√ß√£o de que as t√©cnicas de regulariza√ß√£o (L2 e Dropout) foram eficazes. A interrup√ß√£o precoce das curvas, se o *Early Stopping* foi acionado, confirma que o modelo parou antes de entrar em *overfitting* severo, resultando em um modelo **est√°vel e com alta capacidade de generaliza√ß√£o**. 

### 4.5. Avalia√ß√£o Final da Robustez

Os blocos finais de c√≥digo s√£o dedicados √† plotagem das curvas de desempenho do modelo otimizado (com L2 e *Dropout*):

1.  **Curva de Acur√°cia Otimizada:** A an√°lise visual desta nova curva √© essencial para determinar se as t√©cnicas de regulariza√ß√£o foram eficazes em suavizar as oscila√ß√µes e **reduzir a lacuna (*gap*)** entre a acur√°cia de treino e a acur√°cia de valida√ß√£o. Uma lacuna menor indica um modelo que generaliza melhor para dados n√£o vistos.
2.  **Curva de Perda Otimizada:** O objetivo final √© observar se a perda de valida√ß√£o **n√£o aumenta drasticamente** ap√≥s um certo n√∫mero de √©pocas, mantendo-se mais pr√≥xima da perda de treinamento. Se esta curva for notavelmente mais est√°vel do que a do modelo base, confirma-se que a regulariza√ß√£o **mitigou o *overfitting***, resultando em um modelo mais robusto e com maior poder preditivo em cen√°rios reais. 

# 5. ‚úÖ Avalia√ß√£o Final do Modelo

Este bloco de c√≥digo representa a fase final do ciclo de Machine Learning, onde o desempenho do modelo bin√°rio otimizado √© **avaliado de forma abrangente e imparcial** utilizando o conjunto de teste (`X_test`), que permaneceu in√©dito. O foco est√° na an√°lise de m√©tricas que v√£o al√©m da acur√°cia simples, sendo o **Recall** e a **Matriz de Confus√£o** os elementos centrais para a tomada de decis√£o em um contexto m√©dico.

### Resumo das A√ß√µes de Avalia√ß√£o e M√©tricas Chave

A avalia√ß√£o final √© realizada no conjunto de teste para determinar a efic√°cia do modelo otimizado, conforme detalhado abaixo:

| M√©trica / A√ß√£o | Descri√ß√£o T√©cnica | Relev√¢ncia no Contexto M√©dico |
| :--- | :--- | :--- |
| **Gera√ß√£o de Previs√µes** | A sa√≠da Sigmoid (probabilidades cont√≠nuas) √© convertida em classes bin√°rias definitivas (**0** ou **1**) atrav√©s da fun√ß√£o de arredondamento (`np.round`). | Transforma a probabilidade do modelo na **classe final de previs√£o**, necess√°ria para o c√°lculo de todas as m√©tricas discretas. |
| **Acur√°cia Geral** | Mede a propor√ß√£o total de previs√µes corretas (VP + VN) em rela√ß√£o ao total de amostras. | Fornece uma vis√£o inicial da performance geral do modelo. |
| **Relat√≥rio de Classifica√ß√£o** | Fornece m√©tricas detalhadas (Precis√£o, Recall e F1-Score) por classe. | Permite uma **an√°lise granular** da performance, essencial para validar a Precis√£o e o Recall em desequil√≠brio de classes. |
| **Recall (Sensibilidade)** | Propor√ß√£o de casos **Positivos Reais** que foram corretamente identificados (VP / (VP + FN)). | **M√©trica mais crucial:** Um **Recall alto** minimiza os **Falsos Negativos (FN)** ‚Äî paciente doente diagnosticado como saud√°vel ‚Äî o que representa o **erro mais cr√≠tico** e de maior consequ√™ncia em diagn√≥stico m√©dico. |
| **Matriz de Confus√£o** | Visualizada como um Heatmap, compara as previs√µes do modelo com os valores verdadeiros (VP, VN, FP, FN). | Ferramenta fundamental para **entender a natureza e a distribui√ß√£o dos erros** do modelo, servindo como base visual para a interpreta√ß√£o do Recall e da Precis√£o. |

---

### Detalhamento da Avalia√ß√£o e An√°lise da Matriz de Confus√£o

#### Gera√ß√£o de Previs√µes e Acur√°cia Geral

O c√≥digo inicia com a **gera√ß√£o das previs√µes** (`binary_pred`) aplicando uma fun√ß√£o **`np.round`** na sa√≠da da camada Sigmoid. Esta etapa de arredondamento converte as probabilidades cont√≠nuas em classes bin√°rias discretas (0 ou 1), permitindo o uso das m√©tricas de classifica√ß√£o. Em seguida, a **Acur√°cia Geral** √© impressa. Embora seja uma m√©trica inicial √∫til, ela √© insuficiente e pode ser enganosa em *datasets* onde as classes n√£o est√£o perfeitamente balanceadas, justificando o uso do Relat√≥rio de Classifica√ß√£o.

#### Relat√≥rio de Classifica√ß√£o e o Papel do Recall

O **Relat√≥rio de Classifica√ß√£o** (`classification_report`) √© a principal fonte de m√©tricas detalhadas. Ele apresenta o **F1-Score** (que equilibra Precis√£o e Recall), a **Precis√£o** (que mede a confiabilidade das previs√µes positivas) e o **Recall** para cada classe.

O **Recall** √© a m√©trica mais crucial para este trabalho, tamb√©m conhecido como Sensibilidade ou Taxa de Verdadeiros Positivos (TPR). Ele responde √† pergunta: "De todos os pacientes que estavam realmente Doentes, quantos o modelo conseguiu detectar?". Um **Recall alto √© vital** porque minimiza o **Falso Negativo (FN)**, que √© o **Erro Tipo II** ‚Äî o modelo prev√™ 'Saud√°vel' quando o paciente est√° 'Doente'. Perder um diagn√≥stico positivo pode ter consequ√™ncias graves, o que torna a minimiza√ß√£o do FN a prioridade m√°xima do modelo. O Recall, por si s√≥, n√£o se preocupa com os Falsos Positivos, por isso ele √© analisado em conjunto com a Precis√£o.

#### Matriz de Confus√£o e a Natureza dos Erros

A **Matriz de Confus√£o** (`confusion_matrix`) √© calculada e visualizada como um **Heatmap** . Esta visualiza√ß√£o tabular √© fundamental para entender a natureza dos erros do modelo, comparando as previs√µes com a verdade real:

| Componente | Descri√ß√£o T√©cnica | Classifica√ß√£o (Verdadeiro vs. Previsto) | Natureza do Erro |
| :--- | :--- | :--- | :--- |
| **Verdadeiros Positivos (VP)** | O modelo previu 'Doente' corretamente. | Real: Doente, Previsto: Doente | Acerto |
| **Verdadeiros Negativos (VN)** | O modelo previu 'Saud√°vel' corretamente. | Real: Saud√°vel, Previsto: Saud√°vel | Acerto |
| **Falsos Positivos (FP - Erro Tipo I)** | O modelo previu 'Doente', mas o real era 'Saud√°vel'. | Real: Saud√°vel, Previsto: Doente | Erro Tipo I / Alarme Falso |
| **Falsos Negativos (FN - Erro Tipo II)** | O modelo previu 'Saud√°vel', mas o real era 'Doente'. | Real: Doente, Previsto: Saud√°vel | **Erro Cr√≠tico** |

A inspe√ß√£o visual do *heatmap* permite quantificar diretamente os **FN** e **FP**, validando se as t√©cnicas de regulariza√ß√£o L2 e Dropout foram eficazes em manter o FN em n√≠veis aceit√°veis, garantindo que o modelo seja robusto e seguro.

# 6. üìù Conclus√£o sobre a Efic√°cia e a Import√¢ncia da Normaliza√ß√£o

A efic√°cia final do modelo de classifica√ß√£o bin√°ria √© determinada pela an√°lise conjunta das **m√©tricas de teste** (Acur√°cia, Precis√£o, Recall e F1-Score) e pela interpreta√ß√£o da **Matriz de Confus√£o**. Um modelo de alto desempenho √© validado por dois crit√©rios essenciais que foram perseguidos durante o treinamento e otimiza√ß√£o:

1.  **Alta Sensibilidade (Recall para a Classe 'Doente'):** Em problemas de diagn√≥stico m√©dico, a m√©trica mais crucial √© o **Recall** para a classe positiva (Doente). A efic√°cia s√≥ √© confirmada se o modelo apresentar um Recall elevado, garantindo que o n√∫mero de **Falsos Negativos (FN)** seja minimizado. Isso significa que a rede neural est√° detectando corretamente a grande maioria dos casos de doen√ßa, priorizando a seguran√ßa e a interven√ß√£o precoce do paciente.
2.  **Robustez e Generaliza√ß√£o:** A compara√ß√£o das curvas de perda e acur√°cia entre o modelo base e o **modelo regularizado** (com L2 e Dropout) √© o fator decisivo para a robustez. O modelo otimizado s√≥ √© considerado eficaz se apresentar uma **menor diferen√ßa (gap)** entre o desempenho no conjunto de treino e no conjunto de teste. Uma lacuna reduzida indica que as t√©cnicas de regulariza√ß√£o foram bem-sucedidas em mitigar o *overfitting*, garantindo que o modelo n√£o memorizou o ru√≠do dos dados de treinamento e possui uma **alta capacidade de generaliza√ß√£o** para classificar corretamente novos pacientes n√£o vistos.

### Import√¢ncia Cr√≠tica da Normaliza√ß√£o (Padroniza√ß√£o) dos Dados

A **normaliza√ß√£o (ou padroniza√ß√£o)** dos dados, realizada atrav√©s do **`StandardScaler`**, √© de import√¢ncia cr√≠tica e fundamental para o sucesso das Redes Neurais e de muitos outros algoritmos baseados em dist√¢ncia. Sua relev√¢ncia t√©cnica √© dupla e direta:

1.  **Contribui√ß√£o Equitativa das Caracter√≠sticas:** A padroniza√ß√£o transforma os dados, colocando todas as vari√°veis em uma escala compar√°vel, onde a m√©dia √© aproximadamente $0$ ($\mu \approx 0$) e o desvio padr√£o √© aproximadamente $1$ ($\sigma \approx 1$). Isso garante que todas as caracter√≠sticas contribuam **equitativamente** para o c√°lculo do **loss (perda)**.
2.  **Estabilidade e Velocidade de Converg√™ncia:** Sem a normaliza√ß√£o, caracter√≠sticas com valores de magnitude muito grande (por exemplo, colesterol, que pode ser $\approx 300$) dominariam as atualiza√ß√µes de peso durante o processo de treinamento via **Gradient Descent**. Essas *features* com grande escala levariam a gradientes acentuados e, consequentemente, a grandes saltos nos pesos. A **consequ√™ncia direta** disso √© um processo de aprendizado:
    * **Lento:** Otimizador gasta tempo navegando em um espa√ßo de busca alongado.
    * **Inst√°vel:** As atualiza√ß√µes de peso oscilam violentamente.
    * **Sub√≥timo:** O modelo frequentemente converge para um m√≠nimo local inferior ou falha em generalizar bem.

Em suma, a padroniza√ß√£o elimina a depend√™ncia da escala original dos dados, **acelera significativamente a converg√™ncia** do otimizador e **melhora a robustez** da Rede Neural, sendo uma etapa n√£o negoci√°vel para alcan√ßar a efic√°cia m√°xima do modelo. 

## üìÑ Licen√ßa

Este projeto √© de uso acad√™mico e foi desenvolvido exclusivamente para fins educacionais no contexto da disciplina.

## üèõÔ∏è Universidade

**Universidade Federal do Amazonas (UFAM)**  
**Instituto de Computa√ß√£o (IComp)**

‚ú≥Ô∏è *Manaus, 2025*
