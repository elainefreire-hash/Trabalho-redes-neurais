# Trabalho de Redes Neurais

Este reposit√≥rio cont√©m o projeto **"Classifica√ß√£o de Doen√ßas Card√≠acas"**, desenvolvido como parte das atividades acad√™micas da disciplina de Fundamentos de Intelig√™ncia Artificial no Instituto de Computa√ß√£o da Universidade Federal do Amazonas (IComp/UFAM).

## üë• Equipe

| Nome | E-mail |
|------|---------|
| Anna Luisa Antony Afonso | anna.antony@icomp.ufam.edu.br |
| Beatriz Quaresma Athaide | beatriz.quaresma@icomp.ufam.edu.br |
| Elaine de Castro Freire | elaine.freire@icomp.ufam.edu.br |
| Manuela Figueira Batista | manuela.batista@icomp.ufam.edu.br |
| Ra√≠ssa Clara Teixeira Brasil | raissa.brasil@icomp.ufam.edu.br |
| Ruthelene Rodrigues Farias | ruthelene.farias@icomp.ufam.edu.br |

# ü´Ä Classifica√ß√£o de Doen√ßas Card√≠acas com Redes Neurais

Este projeto implementa e avalia um modelo de Rede Neural Sequencial (utilizando Keras) para a classifica√ß√£o bin√°ria de doen√ßa card√≠aca com base em dados cl√≠nicos. O objetivo √© configurar um ambiente robusto, limpar e pr√©-processar o dataset Cleveland, treinar um modelo de Deep Learning e otimiz√°-lo com t√©cnicas de regulariza√ß√£o para garantir a capacidade de generaliza√ß√£o. 

# 1. üõ†Ô∏è Inicializa√ß√£o e Carregamento de Dados

Este bloco de c√≥digo marca o in√≠cio de qualquer projeto robusto de Machine Learning (ML), estabelecendo as bases do ambiente de software e preparando as ferramentas necess√°rias para as fases de pr√©-processamento, an√°lise e modelagem.

***

### Verifica√ß√£o e Gerenciamento de Depend√™ncias

O primeiro objetivo do c√≥digo √© importar todas as bibliotecas Python que servir√£o como a espinha dorsal do projeto. Imediatamente ap√≥s a importa√ß√£o, o c√≥digo imprime as vers√µes de cada uma das principais ferramentas. Essa pr√°tica de **versionamento** √© crucial para garantir a **reprodutibilidade** do ambiente. Caso o c√≥digo precise ser executado em outra m√°quina ou em uma data futura, ter as vers√µes exatas documentadas permite diagnosticar e prevenir erros de compatibilidade.

As bibliotecas importadas e verificadas incluem:

* **`sys`:** Essencialmente para obter informa√ß√µes sobre o ambiente de execu√ß√£o, especialmente a vers√£o do **Python** em uso.
* **`pandas`:** A ferramenta prim√°ria para lidar com **dados tabulares**, convertendo dados brutos em estruturas DataFrames f√°ceis de manipular, limpar e analisar.
* **`numpy`:** Fornece a base para **opera√ß√µes num√©ricas** de alto desempenho, sendo o formato de array fundamental que a maioria dos algoritmos de ML consome.
* **`sklearn` (Scikit-learn):** A biblioteca mais popular para tarefas de ML cl√°ssico, oferecendo uma vasta gama de algoritmos de **classifica√ß√£o**, **regress√£o** e **agrupamento**, al√©m de utilit√°rios para pr√©-processamento.
* **`matplotlib`:** A biblioteca de refer√™ncia para a **cria√ß√£o de gr√°ficos** e visualiza√ß√µes de dados, permitindo a constru√ß√£o de histogramas, gr√°ficos de linha e gr√°ficos de barras.
* **`keras`:** Uma interface de alto n√≠vel usada para construir e treinar **Redes Neurais** de maneira eficiente e amig√°vel.

***

### Prepara√ß√£o para Visualiza√ß√£o e Acesso a Dados

A se√ß√£o seguinte, conforme descrito na sua explica√ß√£o, foca em configurar o acesso aos dados e armar o ambiente com as ferramentas de An√°lise Explorat√≥ria de Dados (EDA).

* **Montagem do Google Drive:** Em plataformas de *notebook* baseadas em nuvem, este comando √© fundamental para **conectar o ambiente de c√≥digo** aos arquivos de dados do projeto, permitindo que os dados brutos sejam carregados.
* **Importa√ß√µes Gr√°ficas Avan√ßadas:**
    * As importa√ß√µes de **`matplotlib.pyplot`** e **`seaborn`** s√£o feitas para equipar o projeto com capacidades de visualiza√ß√£o de dados. O `seaborn` √© constru√≠do sobre o `matplotlib` e permite criar **gr√°ficos estat√≠sticos complexos** com menos c√≥digo, sendo ideal para a EDA.
    * A importa√ß√£o de **`pandas.plotting.scatter_matrix`** √© um atalho pr√°tico para gerar uma **matriz de gr√°ficos de dispers√£o**, o que permite inspecionar rapidamente as rela√ß√µes de correla√ß√£o entre todos os pares de vari√°veis num√©ricas do *dataset*.

Em resumo, o bloco de "Inicializa√ß√£o e Carregamento de Dados" est√° configurando o *pipeline* do projeto. Ele verifica a integridade do ambiente, garante que o acesso √† fonte de dados esteja estabelecido e importa as bibliotecas especializadas que ser√£o usadas nas pr√≥ximas etapas de An√°lise Explorat√≥ria e Modelagem.

# 2. üìä Importa√ß√£o e Explora√ß√£o do Dataset
O foco desta etapa √© a limpeza, transforma√ß√£o e an√°lise explorat√≥ria dos dados brutos.


| Etapa                     | Descri√ß√£o                                                                                                                                                                                                                                                                          | Import√¢ncia                                                                                     |
|---------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| Carregamento e Limpeza    | O dataset √© carregado (ex: 303 amostras, 14 colunas). Valores ausentes, codificados como '?', s√£o substitu√≠dos por NaN e, em seguida, as linhas com valores nulos s√£o removidas (resultando em ‚âà297 linhas).                                                                        | Garante a integridade dos dados e remove inconsist√™ncias.                                        |
| Transforma√ß√£o de Tipo     | Todas as colunas s√£o convertidas do tipo object para tipos num√©ricos (int64 ou float64), passo fundamental para permitir o c√°lculo e a modelagem.                                                                                                                                   | Essencial para o uso em algoritmos de Machine Learning.                                         |
| Estat√≠sticas Descritivas  | data.describe() gera um resumo estat√≠stico (mean, std, min, max), crucial para identificar a escala das vari√°veis e planejar o scaling.                                                                                                                                             | Auxilia na detec√ß√£o de outliers e no pr√©-processamento.                                         |
| An√°lise de Distribui√ß√£o   | data.hist() plota histogramas para a an√°lise visual da distribui√ß√£o de frequ√™ncia de cada vari√°vel.                                                                                                                                                                                  | Essencial para verificar o balanceamento da classe alvo (target).                               |
| An√°lise de Correla√ß√£o     | A matriz de correla√ß√£o de Pearson √© calculada e visualizada em um Heatmap.                                                                                                                                                                                                          | Identifica os preditores mais fortes (alta correla√ß√£o com target) e a multicolinearidade.       |
| An√°lise Espec√≠fica        | pd.crosstab e gr√°ficos de barras/pontos exploram rela√ß√µes cruciais (ex: casos positivos/negativos por idade, e a tend√™ncia de thalach (frequ√™ncia card√≠aca m√°xima) em rela√ß√£o √† idade).                                                                                              | Oferece insights diretos e valida a coer√™ncia fisiol√≥gica dos dados.                             |

---
### Detalhamento das Etapas de Pr√©-processamento

#### 1. Limpeza e Integridade dos Dados

O processo de carregamento utiliza o `pandas` para ler o arquivo `heart.csv`. A inspe√ß√£o inicial revela que o *dataset* cont√©m valores ausentes codificados de forma n√£o padr√£o (o caractere **'?'**). O c√≥digo soluciona este problema **substituindo** e, em seguida, **removendo** as linhas que continham esses valores inv√°lidos (`dropna`). Adicionalmente, a remo√ß√£o de **linhas duplicadas** √© realizada para garantir que o modelo n√£o seja treinado com informa√ß√µes redundantes, o que poderia enviesar a avalia√ß√£o de desempenho.

#### 2. Normaliza√ß√£o de Tipos e Estat√≠stica Descritiva

A convers√£o de tipos de dados (`data.apply(pd.to_numeric)`) √© um passo n√£o negoci√°vel no pr√©-processamento, pois garante que todas as colunas estejam em formato **num√©rico** (`int64` ou `float64`), requisito b√°sico para o c√°lculo de dist√¢ncia e otimiza√ß√£o em algoritmos de Machine Learning. Uma vez limpo e tipado, o DataFrame √© resumido pelo **`data.describe()`**. Este resumo estat√≠stico √© inspecionado para:
* Confirmar a **escala** de cada vari√°vel.
* Avaliar a **dispers√£o** (`std`).
* Identificar **valores extremos** (*outliers*) nos valores m√≠nimos e m√°ximos, que podem exigir tratamento especializado (como *winsorizing* ou logaritmiza√ß√£o) posteriormente.

---

### Detalhamento da An√°lise Explorat√≥ria (EDA)

A EDA √© a fase visual e estat√≠stica que fundamenta as decis√µes de modelagem:

#### Distribui√ß√µes e Frequ√™ncias
A gera√ß√£o de **histogramas** (`data.hist()`) √© utilizada para visualizar a distribui√ß√£o de frequ√™ncia de cada vari√°vel. Esta an√°lise √© essencial para entender se os dados seguem uma **distribui√ß√£o normal** e, sobretudo, para inspecionar o **balanceamento da vari√°vel alvo (`target`)**. Um *target* desbalanceado (onde uma classe √© muito mais frequente que a outra) pode levar o modelo a ser enviesado, necessitando de t√©cnicas de reamostragem como SMOTE.

#### An√°lise de Rela√ß√µes e Coer√™ncia
* **Correla√ß√£o (Heatmap):** A matriz de correla√ß√£o de Pearson, exibida como um **Heatmap**, permite identificar de forma r√°pida quais vari√°veis t√™m a **maior rela√ß√£o linear** com o `target`. Al√©m disso, √© o principal m√©todo para detectar a **multicolinearidade** (correla√ß√£o alta entre dois preditores independentes), que pode inflacionar a vari√¢ncia e prejudicar a interpretabilidade de modelos como Regress√£o Log√≠stica.
* **Idade vs. Doen√ßa (`pd.crosstab`):** O cruzamento da vari√°vel categ√≥rica `age` com o `target` √© plotado para identificar as **faixas et√°rias de maior risco**. Este *insight* direto valida a import√¢ncia preditiva dessa *feature*.
* **Valida√ß√£o Fisiol√≥gica (`thalach` vs. Idade):** A plotagem da frequ√™ncia card√≠aca m√°xima (`thalach`) em fun√ß√£o da idade √© uma etapa de **valida√ß√£o de qualidade**. A expectativa √© que essa vari√°vel **diminua** com o avan√ßo da idade, um comportamento fisiol√≥gico conhecido. A confirma√ß√£o dessa tend√™ncia no *dataset* atesta a coer√™ncia e a integridade dos dados coletados.

# 3. üß† Cria√ß√£o dos Dados de Treinamento

Este bloco de c√≥digo √© o ponto de transi√ß√£o crucial entre a An√°lise Explorat√≥ria de Dados (EDA) e a fase de Modelagem. Ele cobre as etapas essenciais de **estrutura√ß√£o, divis√£o e escalonamento** das vari√°veis, garantindo que o *dataset* esteja no formato ideal para o treinamento e a avalia√ß√£o dos algoritmos de Machine Learning.

### 3.1. Separa√ß√£o de Vari√°veis e Convers√£o para NumPy

A primeira a√ß√£o do c√≥digo √© estabelecer o problema de classifica√ß√£o atrav√©s da separa√ß√£o formal das vari√°veis. A coluna **`target`** √© isolada para formar a vari√°vel **y** (o r√≥tulo, ou o que deve ser previsto), enquanto todas as demais colunas do DataFrame, que representam as caracter√≠sticas cl√≠nicas, s√£o agrupadas na matriz **X** (os preditores). O c√≥digo, em seguida, realiza a convers√£o imediata de **X** e **y** para **NumPy Arrays**. Essa convers√£o √© um requisito t√©cnico fundamental, pois o NumPy √© o formato de matriz de alto desempenho exigido por praticamente todas as bibliotecas de Machine Learning, como Scikit-learn e Keras, otimizando o consumo de mem√≥ria e a velocidade dos c√°lculos. A inspe√ß√£o inicial de `X[0]` confirma que o processo de separa√ß√£o ocorreu com sucesso e que os dados num√©ricos est√£o estruturados corretamente.

### 3.2. Divis√£o Estratificada dos Dados (*Train-Test Split*)

A pr√≥xima etapa √© a divis√£o dos dados em conjuntos de **treinamento (`X_train`, `y_train`)** e **teste (`X_test`, `y_test`)**. O padr√£o utilizado √© de **80%** dos dados para treinamento e **20%** para teste (`test_size=0.2`). Esta separa√ß√£o √© vital para que o modelo seja treinado em uma por√ß√£o dos dados e avaliado em uma por√ß√£o **in√©dita**, fornecendo uma estimativa imparcial de seu desempenho em novos dados. O uso do par√¢metro **`stratify=y` √© absolutamente cr√≠tico** neste contexto de classifica√ß√£o. Ele assegura que a **propor√ß√£o da classe alvo** (pacientes com e sem a doen√ßa card√≠aca) seja **mantida de forma id√™ntica** nos subconjuntos de treino e teste.  Sem a estratifica√ß√£o, o conjunto de teste poderia, por acaso, conter uma propor√ß√£o desequilibrada das classes, resultando em uma avalia√ß√£o de desempenho irrealista ou tendenciosa.

### 3.3. Padroniza√ß√£o de Caracter√≠sticas (*Standard Scaling*) e Preven√ß√£o de *Data Leakage*

A etapa final e mais sofisticada de pr√©-processamento √© a **padroniza√ß√£o** das caracter√≠sticas (`StandardScaler`). Este m√©todo transforma os dados de forma que cada caracter√≠stica tenha uma **m√©dia pr√≥xima de zero e um desvio padr√£o pr√≥ximo de um**. Isso √© essencial para algoritmos que calculam dist√¢ncias entre pontos (como k-Nearest Neighbors, KNN) ou para modelos baseados em otimiza√ß√£o por gradiente (como Redes Neurais), pois impede que *features* com escalas naturalmente maiores (como a idade) dominem o processo de aprendizado.

O processo de *scaling* √© aplicado em duas fases obrigat√≥rias para **prevenir o vazamento de dados (*data leakage*)**:

1.  **Ajuste e Transforma√ß√£o no Treino:** O *scaler* √© **ajustado** e **transformado** (`fit_transform`) **somente** no conjunto de treinamento (`X_train`). Isso significa que a m√©dia e o desvio padr√£o usados para a padroniza√ß√£o s√£o derivados **exclusivamente** dos dados de treino.
2.  **Transforma√ß√£o no Teste:** Os **mesmos par√¢metros** (m√©dia e desvio padr√£o) aprendidos no conjunto de treino s√£o, ent√£o, usados para **transformar** (`transform`) o conjunto de teste (`X_test`).

Essa separa√ß√£o garante que o modelo de avalia√ß√£o (`X_test`) permane√ßa totalmente desconhecido em todas as etapas, simulando com precis√£o o cen√°rio real onde o modelo encontrar√° dados novos. A verifica√ß√£o final do `X[0]` no c√≥digo serve para confirmar que a matriz original **X** n√£o foi modificada pelo `StandardScaler`, mantendo a integridade do *array* principal.      
## üìÑ 4 - Treinamento da Rede Neural

Esta documenta√ß√£o abrange o desenvolvimento completo do modelo de **Deep Learning**, desde a garantia de um ambiente **reprodut√≠vel** at√© a aplica√ß√£o de **t√©cnicas avan√ßadas de regulariza√ß√£o** e a **an√°lise visual** do desempenho. O objetivo √© criar um modelo robusto, com alta capacidade de generaliza√ß√£o e evitar o *overfitting*.

### 4.1. Prepara√ß√£o dos Dados

O processo de prepara√ß√£o dos dados √© fundamental para o sucesso do modelo de classifica√ß√£o bin√°ria. Inicialmente, s√£o criadas c√≥pias dos conjuntos de dados originais (y_train e y_test) para preservar as informa√ß√µes originais e permitir an√°lises futuras. O processo de binariza√ß√£o converte todos os valores maiores que zero, que originalmente representam diferentes n√≠veis ou tipos de doen√ßas card√≠acas, para o valor 1, enquanto mant√©m os valores zero (aus√™ncia de doen√ßa) inalterados. Esta transforma√ß√£o simplifica o problema de classifica√ß√£o multiclasse original, permitindo que o modelo foque exclusivamente na detec√ß√£o da presen√ßa ou aus√™ncia de doen√ßa, independentemente de sua gravidade ou tipo espec√≠fico. A verifica√ß√£o dos primeiros 20 valores ap√≥s a convers√£o serve como controle de qualidade, garantindo que a transforma√ß√£o foi aplicada corretamente e que os dados est√£o no formato esperado para o treinamento do modelo.

### 4.2. Arquitetura e Estrutura da Rede Neura

A arquitetura do modelo implementa uma rede neural do tipo Feed-Forward Neural Network (FFNN) com estrutura sequencial, composta por uma camada de entrada, tr√™s camadas ocultas densas e uma camada de sa√≠da. A camada de entrada recebe 13 features que representam os atributos cl√≠nicos do paciente, como idade, press√£o arterial, n√≠veis de colesterol, entre outros. A primeira camada oculta cont√©m 16 neur√¥nios com fun√ß√£o de ativa√ß√£o ReLU (Rectified Linear Unit), sendo respons√°vel pela extra√ß√£o inicial de caracter√≠sticas de alto n√≠vel dos dados de entrada e identifica√ß√£o de padr√µes nos atributos cl√≠nicos. Esta camada utiliza inicializa√ß√£o de pesos normal (distribui√ß√£o gaussiana), regulariza√ß√£o L2 com par√¢metro lambda de 0.005 e dropout de 40% para prevenir overfitting.

A segunda camada oculta possui 12 neur√¥nios, tamb√©m com ativa√ß√£o ReLU, e tem como fun√ß√£o refinar as caracter√≠sticas extra√≠das pela camada anterior, combinando padr√µes em representa√ß√µes mais abstratas. Mant√©m as mesmas t√©cnicas de regulariza√ß√£o da camada anterior (L2 com lambda=0.005 e dropout de 40%). A terceira camada oculta, uma adi√ß√£o estrat√©gica √† arquitetura, cont√©m 8 neur√¥nios com ativa√ß√£o ReLU e √© respons√°vel pela consolida√ß√£o final das caracter√≠sticas, preparando representa√ß√µes compactas para a decis√£o de classifica√ß√£o. Esta arquitetura progressivamente decrescente (16 ‚Üí 12 ‚Üí 8 neur√¥nios) implementa um padr√£o de encoder, comprimindo informa√ß√µes em representa√ß√µes cada vez mais abstratas e compactas, o que √© particularmente adequado para datasets de tamanho moderado como o utilizado neste projeto.

A camada de sa√≠da utiliza um √∫nico neur√¥nio com fun√ß√£o de ativa√ß√£o sigmoid, que mapeia qualquer valor real para o intervalo [0, 1], permitindo interpreta√ß√£o direta como probabilidade de o paciente ter doen√ßa card√≠aca. Valores pr√≥ximos a 1 indicam alta probabilidade de doen√ßa, enquanto valores pr√≥ximos a 0 indicam aus√™ncia de condi√ß√£o card√≠aca. Esta escolha de fun√ß√£o de ativa√ß√£o √© fundamental para problemas de classifica√ß√£o bin√°ria, pois fornece uma sa√≠da probabil√≠stica que pode ser facilmente interpretada e utilizada para tomada de decis√£o cl√≠nica.

### 4.3. T√©cnicas de Regulariza√ß√£o Implementadas

O modelo incorpora tr√™s t√©cnicas principais de regulariza√ß√£o para prevenir overfitting e melhorar a capacidade de generaliza√ß√£o. O dropout, configurado com taxa de 40% em todas as camadas ocultas, funciona desativando aleatoriamente 40% dos neur√¥nios durante cada √©poca de treinamento, for√ßando a rede a aprender representa√ß√µes mais robustas e redundantes que n√£o dependem exclusivamente de neur√¥nios espec√≠ficos. Esta t√©cnica √© particularmente eficaz em datasets de tamanho moderado, onde o risco de overfitting √© maior.

A regulariza√ß√£o L2 (tamb√©m conhecida como Ridge Regularization) √© aplicada aos pesos de todas as camadas ocultas com par√¢metro lambda de 0.005. Esta t√©cnica adiciona um termo de penaliza√ß√£o proporcional ao quadrado dos pesos na fun√ß√£o de perda, incentivando o modelo a manter pesos pequenos e distribu√≠dos, evitando que alguns pesos dominem excessivamente a decis√£o do modelo. O valor de lambda foi cuidadosamente escolhido para equilibrar a complexidade do modelo com sua capacidade de aprendizado, sendo suficientemente forte para prevenir overfitting mas n√£o t√£o forte a ponto de prejudicar a capacidade de aprendizado do modelo.

O Early Stopping monitora a perda de valida√ß√£o (val_loss) durante o treinamento e interrompe automaticamente o processo quando n√£o h√° melhoria por 10 √©pocas consecutivas (patience=10). Esta t√©cnica √© crucial para evitar treinamento excessivo, pois identifica o ponto ideal onde o modelo alcan√ßou sua melhor performance no conjunto de valida√ß√£o antes de come√ßar a se especializar demais nos dados de treinamento. Adicionalmente, o Early Stopping est√° configurado para restaurar automaticamente os melhores pesos encontrados durante todo o processo de treinamento (restore_best_weights=True), garantindo que o modelo final utilize os par√¢metros que produziram a melhor performance de valida√ß√£o.

### 4.4. Configura√ß√£o de Hiperpar√¢metros e Compila√ß√£o

O modelo √© compilado utilizando a fun√ß√£o de perda binary_crossentropy, que √© matematicamente ideal para problemas de classifica√ß√£o bin√°ria, pois mede a diferen√ßa entre as probabilidades previstas e os valores reais atrav√©s de uma escala logar√≠tmica, penalizando predi√ß√µes incorretas de forma apropriada. O otimizador escolhido √© o Adam (Adaptive Moment Estimation), um algoritmo de otimiza√ß√£o adaptativa que combina as vantagens dos m√©todos AdaGrad e RMSprop, ajustando automaticamente as taxas de aprendizado para cada par√¢metro da rede. A taxa de aprendizado inicial (learning rate) est√° configurada em 0.001, um valor conservador que permite converg√™ncia est√°vel sem oscila√ß√µes excessivas na fun√ß√£o de perda.

Para monitoramento durante o treinamento, a m√©trica de acur√°cia √© utilizada, fornecendo uma medida direta e interpret√°vel do percentual de predi√ß√µes corretas. O treinamento √© configurado para rodar por at√© 100 √©pocas, embora na pr√°tica o Early Stopping geralmente interrompa o processo bem antes deste limite. O tamanho do batch foi definido como 16 amostras, significando que o modelo processa 16 exemplos antes de atualizar seus pesos atrav√©s do algoritmo de backpropagation. Este valor relativamente pequeno de batch size foi escolhido para proporcionar atualiza√ß√µes mais frequentes dos pesos, o que pode ajudar na converg√™ncia em datasets menores e adicionar um efeito de regulariza√ß√£o natural atrav√©s do ru√≠do nas estimativas de gradiente.

### 4.5. Pipeline de Treinamento e Processo de Aprendizado

O processo de treinamento segue um pipeline estruturado que come√ßa com a prepara√ß√£o e valida√ß√£o dos dados bin√°rios, garantindo que os conjuntos de treino e teste est√£o corretamente formatados. Durante a inicializa√ß√£o do modelo, os pesos s√£o atribu√≠dos aleatoriamente seguindo a distribui√ß√£o normal especificada, criando um ponto de partida √∫nico para cada treinamento. O treinamento iterativo ent√£o procede atrav√©s de m√∫ltiplas √©pocas, onde cada √©poca representa uma passagem completa pelo conjunto de dados de treinamento.

Em cada √©poca, o modelo realiza um forward pass para calcular as predi√ß√µes, seguido pelo c√°lculo da perda utilizando a fun√ß√£o binary_crossentropy. Ap√≥s calcular a perda, o algoritmo de backpropagation (backward pass) √© executado para calcular os gradientes de cada peso em rela√ß√£o √† perda, e o otimizador Adam utiliza estes gradientes para atualizar os pesos do modelo. Simultaneamente, o modelo √© avaliado no conjunto de valida√ß√£o (X_test, Y_test_binary) para monitorar sua performance em dados n√£o vistos durante o treinamento.

O callback de Early Stopping monitora continuamente a perda de valida√ß√£o ap√≥s cada √©poca. Quando a val_loss n√£o apresenta melhoria por 10 √©pocas consecutivas, o treinamento √© interrompido automaticamente e os melhores pesos s√£o restaurados. Esta abordagem garante que o modelo final representa o ponto √≥timo de performance, evitando tanto underfitting (parada prematura) quanto overfitting (treinamento excessivo). Todo o hist√≥rico de treinamento, incluindo valores de loss e accuracy para treino e valida√ß√£o em cada √©poca, √© armazenado no objeto history para posterior an√°lise e visualiza√ß√£o.

# 5. ‚úÖ Avalia√ß√£o Final do Modelo

Este bloco de c√≥digo representa a fase final do ciclo de Machine Learning, onde o desempenho do modelo bin√°rio otimizado √© **avaliado de forma abrangente e imparcial** utilizando o conjunto de teste (`X_test`), que permaneceu in√©dito. O foco est√° na an√°lise de m√©tricas que v√£o al√©m da acur√°cia simples, sendo o **Recall** e a **Matriz de Confus√£o** os elementos centrais para a tomada de decis√£o em um contexto m√©dico.

### Resumo das A√ß√µes de Avalia√ß√£o e M√©tricas Chave

A avalia√ß√£o final √© realizada no conjunto de teste para determinar a efic√°cia do modelo otimizado, conforme detalhado abaixo:

| M√©trica / A√ß√£o | Descri√ß√£o T√©cnica | Relev√¢ncia no Contexto M√©dico |
| :--- | :--- | :--- |
| **Gera√ß√£o de Previs√µes** | A sa√≠da Sigmoid (probabilidades cont√≠nuas) √© convertida em classes bin√°rias definitivas (**0** ou **1**) atrav√©s da fun√ß√£o de arredondamento (`np.round`). | Transforma a probabilidade do modelo na **classe final de previs√£o**, necess√°ria para o c√°lculo de todas as m√©tricas discretas. |
| **Acur√°cia Geral** | Mede a propor√ß√£o total de previs√µes corretas (VP + VN) em rela√ß√£o ao total de amostras. | Fornece uma vis√£o inicial da performance geral do modelo. |
| **Relat√≥rio de Classifica√ß√£o** | Fornece m√©tricas detalhadas (Precis√£o, Recall e F1-Score) por classe. | Permite uma **an√°lise granular** da performance, essencial para validar a Precis√£o e o Recall em desequil√≠brio de classes. |
| **Recall (Sensibilidade)** | Propor√ß√£o de casos **Positivos Reais** que foram corretamente identificados (VP / (VP + FN)). | **M√©trica mais crucial:** Um **Recall alto** minimiza os **Falsos Negativos (FN)** ‚Äî paciente doente diagnosticado como saud√°vel ‚Äî o que representa o **erro mais cr√≠tico** e de maior consequ√™ncia em diagn√≥stico m√©dico. |
| **Matriz de Confus√£o** | Visualizada como um Heatmap, compara as previs√µes do modelo com os valores verdadeiros (VP, VN, FP, FN). | Ferramenta fundamental para **entender a natureza e a distribui√ß√£o dos erros** do modelo, servindo como base visual para a interpreta√ß√£o do Recall e da Precis√£o. |

---

### Detalhamento da Avalia√ß√£o e An√°lise da Matriz de Confus√£o

#### Gera√ß√£o de Previs√µes e Acur√°cia Geral

O c√≥digo inicia com a **gera√ß√£o das previs√µes** (`binary_pred`) aplicando uma fun√ß√£o **`np.round`** na sa√≠da da camada Sigmoid. Esta etapa de arredondamento converte as probabilidades cont√≠nuas em classes bin√°rias discretas (0 ou 1), permitindo o uso das m√©tricas de classifica√ß√£o. Em seguida, a **Acur√°cia Geral** √© impressa. Embora seja uma m√©trica inicial √∫til, ela √© insuficiente e pode ser enganosa em *datasets* onde as classes n√£o est√£o perfeitamente balanceadas, justificando o uso do Relat√≥rio de Classifica√ß√£o.

#### Relat√≥rio de Classifica√ß√£o e o Papel do Recall

O **Relat√≥rio de Classifica√ß√£o** (`classification_report`) √© a principal fonte de m√©tricas detalhadas. Ele apresenta o **F1-Score** (que equilibra Precis√£o e Recall), a **Precis√£o** (que mede a confiabilidade das previs√µes positivas) e o **Recall** para cada classe.

O **Recall** √© a m√©trica mais crucial para este trabalho, tamb√©m conhecido como Sensibilidade ou Taxa de Verdadeiros Positivos (TPR). Ele responde √† pergunta: "De todos os pacientes que estavam realmente Doentes, quantos o modelo conseguiu detectar?". Um **Recall alto √© vital** porque minimiza o **Falso Negativo (FN)**, que √© o **Erro Tipo II** ‚Äî o modelo prev√™ 'Saud√°vel' quando o paciente est√° 'Doente'. Perder um diagn√≥stico positivo pode ter consequ√™ncias graves, o que torna a minimiza√ß√£o do FN a prioridade m√°xima do modelo. O Recall, por si s√≥, n√£o se preocupa com os Falsos Positivos, por isso ele √© analisado em conjunto com a Precis√£o.

#### Matriz de Confus√£o e a Natureza dos Erros

A **Matriz de Confus√£o** (`confusion_matrix`) √© calculada e visualizada como um **Heatmap** . Esta visualiza√ß√£o tabular √© fundamental para entender a natureza dos erros do modelo, comparando as previs√µes com a verdade real:

| Componente | Descri√ß√£o T√©cnica | Classifica√ß√£o (Verdadeiro vs. Previsto) | Natureza do Erro |
| :--- | :--- | :--- | :--- |
| **Verdadeiros Positivos (VP)** | O modelo previu 'Doente' corretamente. | Real: Doente, Previsto: Doente | Acerto |
| **Verdadeiros Negativos (VN)** | O modelo previu 'Saud√°vel' corretamente. | Real: Saud√°vel, Previsto: Saud√°vel | Acerto |
| **Falsos Positivos (FP - Erro Tipo I)** | O modelo previu 'Doente', mas o real era 'Saud√°vel'. | Real: Saud√°vel, Previsto: Doente | Erro Tipo I / Alarme Falso |
| **Falsos Negativos (FN - Erro Tipo II)** | O modelo previu 'Saud√°vel', mas o real era 'Doente'. | Real: Doente, Previsto: Saud√°vel | **Erro Cr√≠tico** |

A inspe√ß√£o visual do *heatmap* permite quantificar diretamente os **FN** e **FP**, validando se as t√©cnicas de regulariza√ß√£o L2 e Dropout foram eficazes em manter o FN em n√≠veis aceit√°veis, garantindo que o modelo seja robusto e seguro.

# 6. üìù Conclus√£o sobre a Efic√°cia e a Import√¢ncia da Normaliza√ß√£o

A efic√°cia final do modelo de classifica√ß√£o bin√°ria √© determinada pela an√°lise conjunta das **m√©tricas de teste** (Acur√°cia, Precis√£o, Recall e F1-Score) e pela interpreta√ß√£o da **Matriz de Confus√£o**. Um modelo de alto desempenho √© validado por dois crit√©rios essenciais que foram perseguidos durante o treinamento e otimiza√ß√£o:

1.  **Alta Sensibilidade (Recall para a Classe 'Doente'):** Em problemas de diagn√≥stico m√©dico, a m√©trica mais crucial √© o **Recall** para a classe positiva (Doente). A efic√°cia s√≥ √© confirmada se o modelo apresentar um Recall elevado, garantindo que o n√∫mero de **Falsos Negativos (FN)** seja minimizado. Isso significa que a rede neural est√° detectando corretamente a grande maioria dos casos de doen√ßa, priorizando a seguran√ßa e a interven√ß√£o precoce do paciente.
2.  **Robustez e Generaliza√ß√£o:** A compara√ß√£o das curvas de perda e acur√°cia entre o modelo base e o **modelo regularizado** (com L2 e Dropout) √© o fator decisivo para a robustez. O modelo otimizado s√≥ √© considerado eficaz se apresentar uma **menor diferen√ßa (gap)** entre o desempenho no conjunto de treino e no conjunto de teste. Uma lacuna reduzida indica que as t√©cnicas de regulariza√ß√£o foram bem-sucedidas em mitigar o *overfitting*, garantindo que o modelo n√£o memorizou o ru√≠do dos dados de treinamento e possui uma **alta capacidade de generaliza√ß√£o** para classificar corretamente novos pacientes n√£o vistos.

### Import√¢ncia Cr√≠tica da Normaliza√ß√£o (Padroniza√ß√£o) dos Dados

A **normaliza√ß√£o (ou padroniza√ß√£o)** dos dados, realizada atrav√©s do **`StandardScaler`**, √© de import√¢ncia cr√≠tica e fundamental para o sucesso das Redes Neurais e de muitos outros algoritmos baseados em dist√¢ncia. Sua relev√¢ncia t√©cnica √© dupla e direta:

1.  **Contribui√ß√£o Equitativa das Caracter√≠sticas:** A padroniza√ß√£o transforma os dados, colocando todas as vari√°veis em uma escala compar√°vel, onde a m√©dia √© aproximadamente $0$ ($\mu \approx 0$) e o desvio padr√£o √© aproximadamente $1$ ($\sigma \approx 1$). Isso garante que todas as caracter√≠sticas contribuam **equitativamente** para o c√°lculo do **loss (perda)**.
2.  **Estabilidade e Velocidade de Converg√™ncia:** Sem a normaliza√ß√£o, caracter√≠sticas com valores de magnitude muito grande (por exemplo, colesterol, que pode ser $\approx 300$) dominariam as atualiza√ß√µes de peso durante o processo de treinamento via **Gradient Descent**. Essas *features* com grande escala levariam a gradientes acentuados e, consequentemente, a grandes saltos nos pesos. A **consequ√™ncia direta** disso √© um processo de aprendizado:
    * **Lento:** Otimizador gasta tempo navegando em um espa√ßo de busca alongado.
    * **Inst√°vel:** As atualiza√ß√µes de peso oscilam violentamente.
    * **Sub√≥timo:** O modelo frequentemente converge para um m√≠nimo local inferior ou falha em generalizar bem.

Em suma, a padroniza√ß√£o elimina a depend√™ncia da escala original dos dados, **acelera significativamente a converg√™ncia** do otimizador e **melhora a robustez** da Rede Neural, sendo uma etapa n√£o negoci√°vel para alcan√ßar a efic√°cia m√°xima do modelo. 

## üìÑ Licen√ßa

Este projeto √© de uso acad√™mico e foi desenvolvido exclusivamente para fins educacionais no contexto da disciplina.

## üèõÔ∏è Universidade

**Universidade Federal do Amazonas (UFAM)**  
**Instituto de Computa√ß√£o (IComp)**

‚ú≥Ô∏è *Manaus, 2025*
