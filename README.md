# Trabalho de Redes Neurais

Este reposit√≥rio cont√©m o projeto **"Classifica√ß√£o de Doen√ßas Card√≠acas"**, desenvolvido como parte das atividades acad√™micas da disciplina de Fundamentos de Intelig√™ncia Artificial no Instituto de Computa√ß√£o da Universidade Federal do Amazonas (IComp/UFAM).

## üë• Equipe

| Nome | E-mail |
|------|---------|
| Anna Luisa Antony Afonso | anna.antony@icomp.ufam.edu.br |
| Beatriz Quaresma Athaide | beatriz.quaresma@icomp.ufam.edu.br |
| Elaine de Castro Freire | elaine.freire@icomp.ufam.edu.br |
| Manuela Figueira Batista | manuela.batista@icomp.ufam.edu.br |
| Ra√≠ssa Clara Teixeira Brasil | raissa.brasil@icomp.ufam.edu.br |
| Ruthelene Rodrigues Farias | ruthelene.farias@icomp.ufam.edu.br |

# ü´Ä Classifica√ß√£o de Doen√ßas Card√≠acas com Redes Neurais


Este projeto implementa e avalia um modelo de Rede Neural Sequencial (utilizando Keras) para a classifica√ß√£o bin√°ria de doen√ßa card√≠aca com base em dados cl√≠nicos. O objetivo √© configurar um ambiente robusto, limpar e pr√©-processar o dataset Cleveland, treinar um modelo de Deep Learning e otimiz√°-lo com t√©cnicas de regulariza√ß√£o para garantir a capacidade de generaliza√ß√£o. 

# 1. üõ†Ô∏è Inicializa√ß√£o e Carregamento de Dados


Esta se√ß√£o estabelece o ambiente de execu√ß√£o, garantindo a reprodutibilidade do projeto.

Verifica√ß√£o de Vers√µes: O c√≥digo importa e exibe as vers√µes das principais bibliotecas utilizadas, como sys, pandas, numpy, sklearn, matplotlib, e keras. Esta √© uma pr√°tica recomendada para evitar problemas de compatibilidade e documentar o ambiente.

Setup: O ambiente √© configurado com a montagem do Google Drive (para acesso aos dados) e a importa√ß√£o das bibliotecas de visualiza√ß√£o matplotlib.pyplot e seaborn para a cria√ß√£o de gr√°ficos estat√≠sticos, e pandas.plotting.scatter_matrix para an√°lise de dispers√£o.

# 2. üìä Importa√ß√£o e Explora√ß√£o do Dataset
O foco desta etapa √© a limpeza, transforma√ß√£o e an√°lise explorat√≥ria dos dados brutos.


| Etapa                     | Descri√ß√£o                                                                                                                                                                                                                                                                          | Import√¢ncia                                                                                     |
|---------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|
| Carregamento e Limpeza    | O dataset √© carregado (ex: 303 amostras, 14 colunas). Valores ausentes, codificados como '?', s√£o substitu√≠dos por NaN e, em seguida, as linhas com valores nulos s√£o removidas (resultando em ‚âà297 linhas).                                                                        | Garante a integridade dos dados e remove inconsist√™ncias.                                        |
| Transforma√ß√£o de Tipo     | Todas as colunas s√£o convertidas do tipo object para tipos num√©ricos (int64 ou float64), passo fundamental para permitir o c√°lculo e a modelagem.                                                                                                                                   | Essencial para o uso em algoritmos de Machine Learning.                                         |
| Estat√≠sticas Descritivas  | data.describe() gera um resumo estat√≠stico (mean, std, min, max), crucial para identificar a escala das vari√°veis e planejar o scaling.                                                                                                                                             | Auxilia na detec√ß√£o de outliers e no pr√©-processamento.                                         |
| An√°lise de Distribui√ß√£o   | data.hist() plota histogramas para a an√°lise visual da distribui√ß√£o de frequ√™ncia de cada vari√°vel.                                                                                                                                                                                  | Essencial para verificar o balanceamento da classe alvo (target).                               |
| An√°lise de Correla√ß√£o     | A matriz de correla√ß√£o de Pearson √© calculada e visualizada em um Heatmap.                                                                                                                                                                                                          | Identifica os preditores mais fortes (alta correla√ß√£o com target) e a multicolinearidade.       |
| An√°lise Espec√≠fica        | pd.crosstab e gr√°ficos de barras/pontos exploram rela√ß√µes cruciais (ex: casos positivos/negativos por idade, e a tend√™ncia de thalach (frequ√™ncia card√≠aca m√°xima) em rela√ß√£o √† idade).                                                                                              | Oferece insights diretos e valida a coer√™ncia fisiol√≥gica dos dados.                             |


# 3. üß† Cria√ß√£o dos Dados de Treinamento


Nesta se√ß√£o, os dados s√£o estruturados para o treinamento do modelo.
1. Separa√ß√£o de Preditores e Alvo: A coluna target √© separada para formar a vari√°vel alvo y, e o restante das colunas forma a matriz de caracter√≠sticas X. Ambas s√£o convertidas em arrays NumPy.
2. Divis√£o Estratificada: O train_test_split divide o dataset em conjuntos de treino ($\approx 80\%$) e teste ($\approx 20\%$). O par√¢metro stratify=y √© crucial para garantir que a propor√ß√£o da classe alvo seja mantida consistentemente nos subconjuntos.
3. Padroniza√ß√£o (Scaling): O StandardScaler √© usado para padronizar as caracter√≠sticas (m√©dia $\approx 0$, desvio padr√£o $\approx 1$). √â aplicado ajustando-o apenas no conjunto de treino (fit_transform) e depois aplicado (transform) ao conjunto de teste (X_test), evitando vazamento de dados (data leakage).
4. Import√¢ncia da Padroniza√ß√£o: Este passo √© vital para o desempenho de Redes Neurais, pois garante que todas as caracter√≠sticas contribuam igualmente para o c√°lculo do loss, facilitando a converg√™ncia do gradient descent (ver Se√ß√£o 6).

# 4. üìà Treinamento e Otimiza√ß√£o da Rede Neural


Esta etapa foca na defini√ß√£o, treinamento e otimiza√ß√£o do modelo de Deep Learning para a classifica√ß√£o bin√°ria.                                                                                             


**Arquitetura Base (Modelo 1)**
1. Estrutura: Modelo Sequencial com duas camadas ocultas ([16] -> [8] neur√¥nios) e ativa√ß√£o ReLU. Uma camada de Dropout(0.2) √© adicionada para prevenir overfitting inicial.
2. Camada de Sa√≠da: 1 neur√¥nio com ativa√ß√£o sigmoid (ideal para classifica√ß√£o bin√°ria).
3. Compila√ß√£o: Fun√ß√£o de perda binary_crossentropy, otimizador adam, e m√©trica accuracy.


**Treinamento (Modelo 2)**
1. Nova Estrutura: Uma terceira camada oculta ([16] -> [8] -> [4] neur√¥nios) √© adicionada na tentativa de capturar rela√ß√µes mais complexas.
2. Alvo Bin√°rio: O alvo √© redefinido para garantir que todos os casos de doen√ßa sejam rotulados estritamente como 1 (aus√™ncia como 0), essencial para a fun√ß√£o binary_crossentropy.
3. Treinamento: O modelo √© treinado (model.fit) por 50 √©pocas com um batch_size de 10. O validation_data (X_test, Y_test) √© usado para monitorar o desempenho.
4. An√°lise de Curvas: As curvas de Acur√°cia e Loss (train vs. test) s√£o plotadas. Uma diverg√™ncia crescente entre as curvas (train subindo/loss caindo e test estabilizando/loss subindo) √© um indicativo de overfitting.


**Otimiza√ß√£o e Regulariza√ß√£o (Modelo Final)**
1. T√©cnicas de Regulariza√ß√£o: O modelo √© otimizado com a introdu√ß√£o de regulariza√ß√£o L2 (regularizers.l2(0.001)) nas camadas densas e um aumento no Dropout (de 0.2 para 0.25). O learning rate do otimizador Adam √© ajustado para 0.001.
2. Objetivo: Penalizar pesos grandes, for√ßando o modelo a ser mais simples e reduzindo o overfitting para melhorar a generaliza√ß√£o.
3. Treinamento Otimizado: O modelo final com regulariza√ß√£o √© treinado novamente e suas curvas de Acur√°cia e Loss s√£o plotadas para confirmar se as t√©cnicas de otimiza√ß√£o reduziram a lacuna entre o desempenho de treino e teste.

# 5. ‚úÖ Avalia√ß√£o Final do Modelo


A avalia√ß√£o final √© realizada no conjunto de teste para determinar a efic√°cia do modelo otimizado.


| M√©trica                  | Descri√ß√£o                                                                                                                           | Relev√¢ncia no Contexto M√©dico                                                                                                                                                   |
|--------------------------|---------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Previs√µes                | A sa√≠da sigmoid (probabilidades) √© convertida em classes bin√°rias (0 ou 1) atrav√©s do arredondamento.                               | Classe final de previs√£o.                                                                                                                                                        |
| Relat√≥rio de Classifica√ß√£o | Fornece Precis√£o, Recall e F1-Score por classe.                                                                                    | Permite uma an√°lise granular da performance.                                                                                                                                     |
| Recall (Sensibilidade)   | Propor√ß√£o de casos Positivos Reais que foram corretamente identificados.                                                             | **Crucial para problemas m√©dicos.** Um Recall alto minimiza Falsos Negativos (FN) ‚Äî paciente doente diagnosticado como saud√°vel ‚Äî que podem ter consequ√™ncias graves.           |
| Matriz de Confus√£o       | Visualizada como um Heatmap, compara as previs√µes do modelo com os valores verdadeiros (VP, VN, FP, FN).                            | Ferramenta fundamental para entender a natureza dos erros do modelo e calcular as m√©tricas de desempenho.                                                                       |


**Componentes da Matriz de Confus√£o:**


1. Verdadeiros Positivos (VP): Doente, previsto como Doente (Acerto).
2. Verdadeiros Negativos (VN): Saud√°vel, previsto como Saud√°vel (Acerto).
3. Falsos Positivos (FP - Erro Tipo I): Saud√°vel, previsto como Doente (Erro).
4. Falsos Negativos (FN - Erro Tipo II): Doente, previsto como Saud√°vel (Erro Cr√≠tico).

# 6. üìù Conclus√£o sobre a Efic√°cia e a Import√¢ncia da Normaliza√ß√£o
**Efic√°cia do Modelo**


A efic√°cia do modelo √© validada se o Recall para a classe 'Doente' for alto e se o modelo otimizado (com L2 e Dropout) apresentar uma menor diferen√ßa entre o desempenho de treino e teste em compara√ß√£o com o modelo base. Isso indica que:
1. O modelo est√° detectando corretamente a maioria dos casos de doen√ßa (alto Recall).
2. O modelo tem uma alta capacidade de generaliza√ß√£o, ou seja, funciona bem com novos pacientes.


**Import√¢ncia da Normaliza√ß√£o/Padroniza√ß√£o dos Dados**


A padroniza√ß√£o com o StandardScaler √© de import√¢ncia cr√≠tica para o sucesso das Redes Neurais:
1. Contribui√ß√£o Equitativa: Garante que todas as caracter√≠sticas (vari√°veis cl√≠nicas) contribuam igualmente para o c√°lculo da perda (loss).
2. Estabilidade do Treinamento: Sem a normaliza√ß√£o, caracter√≠sticas com escalas muito diferentes (ex: idade vs. colesterol) dominariam as atualiza√ß√µes de peso durante o gradient descent.
3. Consequ√™ncia: Isso levaria a um processo de aprendizado lento, inst√°vel e, frequentemente, a uma converg√™ncia para resultados sub√≥timos ou a um modelo que n√£o generaliza bem. A padroniza√ß√£o coloca todas as vari√°veis em uma escala compar√°vel (m√©dia $\approx 0$, desvio padr√£o $\approx 1$), acelerando a converg√™ncia e melhorando a robustez.

## üìÑ Licen√ßa

Este projeto √© de uso acad√™mico e foi desenvolvido exclusivamente para fins educacionais no contexto da disciplina.

## üèõÔ∏è Universidade

**Universidade Federal do Amazonas (UFAM)**  
**Instituto de Computa√ß√£o (IComp)**

‚ú≥Ô∏è *Manaus, 2025*
